# ğŸ–¼ï¸ ClasificaciÃ³n de ImÃ¡genes CIFAR-10 con CNNs

> PrÃ¡ctica 3: Desarrollo sistemÃ¡tico de redes neuronales convolucionales para clasificaciÃ³n de imÃ¡genes

---

## ğŸ“Š Resultados Principales

| MÃ©trica | Valor |
|---------|-------|
| **Mejor Modelo** | CNN Augmentation (2 bloques) |
| **Test Accuracy** | **76-78%** |
| **ParÃ¡metros** | 122,000 |
| **Tiempo/Ã‰poca** | ~4.2s |
| **Mejora vs Baseline** | +26 puntos porcentuales |

### EvoluciÃ³n de Modelos

```
MLP Baseline        â†’  50% accuracy  (789k parÃ¡metros)
CNN Simple (2B)     â†’  72% accuracy  (122k parÃ¡metros) âœ¨ +22%
CNN + L2            â†’  74% accuracy  (+regularizaciÃ³n)
CNN + Augmentation  â†’  78% accuracy  (+4% mÃ¡s crÃ­tico) ğŸ†
CNN Deep (3B)       â†’  78% accuracy  (rendimientos decrecientes)
```

---

## ğŸ¯ CaracterÃ­sticas del Proyecto

### âœ¨ TÃ©cnicas Implementadas

- âœ… **Redes Neuronales Convolucionales** (2 y 3 bloques)
- âœ… **Data Augmentation** (rotaciÃ³n, zoom, traslaciÃ³n, flip)
- âœ… **RegularizaciÃ³n L2** (Î»=1e-4)
- âœ… **Dropout** (rate=0.5)
- âœ… **Learning Rate Scheduling** (ReduceLROnPlateau, CosineDecay)
- âœ… **Early Stopping** con restauraciÃ³n de mejores pesos
- âœ… **ComparaciÃ³n de Optimizadores** (Adam vs SGD+Momentum)
- âœ… **Estudio de AblaciÃ³n** (cuantificaciÃ³n de contribuciones)
- âœ… **AnÃ¡lisis de Errores** (matriz de confusiÃ³n, visualizaciÃ³n)

### ğŸ“ˆ ExperimentaciÃ³n SistemÃ¡tica

| Experimento | Objetivo | Resultado Clave |
|-------------|----------|----------------|
| **PROMPT 1** | Setup y carga de datos | 40k train / 10k valid / 10k test |
| **PROMPT 2** | MLP Baseline | 50% accuracy â†’ necesidad de CNNs |
| **PROMPT 3** | CNN Simple | 72% accuracy (+22% vs MLP) |
| **PROMPT 4** | +L2 + Early Stop | 74% accuracy (reduce overfitting) |
| **PROMPT 5** | +Augmentation + ReduceLR | 78% accuracy â­ |
| **PROMPT 6** | CNN Profunda (3B) | 78% (rendimientos decrecientes) |
| **PROMPT 7** | AnÃ¡lisis de errores | Gatoâ†”Perro confusiÃ³n principal |
| **PROMPT 8** | SGD vs Adam | SGD ligeramente mejor (+0.3%) |
| **PROMPT 9** | Estudio de ablaciÃ³n | Augmentation es la tÃ©cnica mÃ¡s crÃ­tica (-4.2%) |
| **PROMPT 10** | Informe y release | DocumentaciÃ³n completa |

---

## ğŸ† Release Oficial

### ğŸ“¦ [v1.0-P3-CIFAR10](https://github.com/dwp28/IA_P3_CIFAR10_WillsonDaniel/releases/tag/v1.0)

**Contenido del release:**
- ğŸ““ Notebook completo ejecutable (`.ipynb` + `.pdf`)
- ğŸ“Š Resultados completos (`params.yaml`, `metrics.json`, `history_*.csv`)
- ğŸ“¸ Figuras de anÃ¡lisis (curvas, matriz de confusiÃ³n, errores)
- ğŸ“„ Informe ejecutivo (2 pÃ¡ginas)
- ğŸ”§ Archivos de entorno (`requirements.txt`, `ENVIRONMENT.md`)
- ğŸ“¦ **`entrega.zip`**: Paquete completo listo para entrega

---

## ğŸ“ Estructura del Proyecto

```
IA_P3_CIFAR10/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ CIFAR10_CNN_Willson.ipynb    # Notebook principal con todos los prompts
â”‚
â”œâ”€â”€ ğŸ“Š results/
â”‚   â”œâ”€â”€ params.yaml                      # Configuraciones de todos los experimentos
â”‚   â”œâ”€â”€ metrics.json                     # MÃ©tricas completas por modelo
â”‚   â”œâ”€â”€ data_meta.json                   # Metadata y hash de datos
â”‚   â”œâ”€â”€ history_mlp.csv                  # Historial MLP baseline
â”‚   â”œâ”€â”€ history_cnn.csv                  # Historial CNN simple
â”‚   â”œâ”€â”€ history_cnn_l2.csv               # Historial CNN + L2
â”‚   â”œâ”€â”€ history_aug_reduceLR.csv         # Historial CNN + Augmentation
â”‚   â”œâ”€â”€ history_cnn_deep_3blocks.csv     # Historial CNN profunda
â”‚   â”œâ”€â”€ history_sgd_cosine.csv           # Historial SGD + CosineDecay
â”‚   â”œâ”€â”€ classification_report.csv        # MÃ©tricas por clase
â”‚   â”œâ”€â”€ tabla_ablacion.csv               # Resultados del estudio de ablaciÃ³n
â”‚   â””â”€â”€ comparacion_*.csv                # Tablas comparativas
â”‚
â”œâ”€â”€ ğŸ“¸ figuras/
â”‚   â”œâ”€â”€ *_mlp_curvas.png                 # Curvas de aprendizaje MLP
â”‚   â”œâ”€â”€ *_cnn_curvas.png                 # Curvas CNN simple
â”‚   â”œâ”€â”€ *_cnn_l2_early_curvas.png        # Curvas CNN + L2
â”‚   â”œâ”€â”€ *_aug_reduceLR_curvas.png        # Curvas CNN + Augmentation
â”‚   â”œâ”€â”€ *_cnn_deep_3blocks_curvas.png    # Curvas CNN profunda
â”‚   â”œâ”€â”€ *_confusion_matrix_*.png         # Matriz de confusiÃ³n
â”‚   â”œâ”€â”€ *_errores_tipicos_*.png          # VisualizaciÃ³n de errores
â”‚   â”œâ”€â”€ *_adam_vs_sgd_comparison.png     # ComparaciÃ³n optimizadores
â”‚   â”œâ”€â”€ *_ablation_study.png             # Estudio de ablaciÃ³n
â”‚   â””â”€â”€ visualizacion_cifar10.png        # Ejemplos del dataset
â”‚
â”œâ”€â”€ ğŸ’¾ outputs/
â”‚   â”œâ”€â”€ entrega.zip                      # Paquete completo para entrega
â”‚   â”œâ”€â”€ CIFAR10_CNN_Willson.ipynb     # Notebook descargado
â”‚   â”œâ”€â”€ CIFAR10_CNN_Willson.pdf       # PDF del notebook
â”‚   â””â”€â”€ best_model_weights.h5            # Pesos del mejor modelo
â”‚
â”œâ”€â”€ ğŸ”§ env/
â”‚   â”œâ”€â”€ requirements.txt                 # Dependencias congeladas
â”‚   â””â”€â”€ ENVIRONMENT.md                   # Versiones del sistema
â”‚
â”œâ”€â”€ ğŸ“„ README.md                         # Este archivo
â”œâ”€â”€ ğŸ“„ .gitignore                        # Archivos ignorados por Git
â””â”€â”€ ğŸ“„ LICENSE                           # Licencia del proyecto
```

---

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- Python 3.10+
- TensorFlow 2.15+
- GPU (opcional, recomendado para entrenamiento)

### InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/dwp28/IA_P3_CIFAR10_WillsonDaniel.git
cd IA_P3_CIFAR10_WillsonDaniel

# 2. Checkout del release estable
git checkout v1.0-P3-CIFAR10

# 3. Instalar dependencias
pip install -r env/requirements.txt

# 4. Abrir notebook en Colab o Jupyter
jupyter notebook notebooks/CIFAR10_CNN_WillsonDaniel.ipynb
```

### EjecuciÃ³n en Google Colab

1. Ve a [Google Colab](https://colab.research.google.com/)
2. Archivo â†’ Abrir cuaderno â†’ GitHub
3. Pega la URL de este repositorio
4. Selecciona el notebook `CIFAR10_CNN_WillsonDaniel.ipynb`
5. Runtime â†’ Run all

---

## ğŸ”¬ Reproducibilidad

### ConfiguraciÃ³n Garantizada

```python
# Semilla fijada en todas las librerÃ­as
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
```

### Entorno Documentado

- **Python:** 3.10.12
- **TensorFlow:** 2.15.0
- **GPU:** Tesla T4 (15 GB VRAM)
- **Sistema:** Google Colab (Ubuntu 22.04)

### VerificaciÃ³n de Integridad

```bash
# Hash SHA-256 de datos (primeras 1024 imÃ¡genes train)
# Documentado en: results/data_meta.json
```

### EjecuciÃ³n Completa

```bash
# El notebook tarda aproximadamente 45-60 minutos en ejecutarse completo
# (incluye entrenamiento de 5+ modelos)

# Runtime â†’ Factory reset runtime (limpiar memoria)
# Runtime â†’ Run all (ejecutar todas las celdas)
```

---

## ğŸ“Š Resultados Detallados

### Matriz de ConfusiÃ³n (Mejor Modelo)

**Confusiones principales:**

| Par de Clases | Errores Mutuos | RazÃ³n |
|---------------|----------------|-------|
| ğŸ± Gato â†” ğŸ• Perro | 85 | CuadrÃºpedos similares, detalles perdidos a 32Ã—32px |
| ğŸš— Auto â†” ğŸšš CamiÃ³n | 62 | Formas rectangulares, difÃ­cil distinguir tamaÃ±o |
| ğŸ¦Œ Ciervo â†” ğŸ´ Caballo | 48 | Proporciones similares, colores terrosos |

**Clases mÃ¡s fÃ¡ciles:**
- ğŸš¢ Barco (F1=0.87) - Fondo de agua distintivo
- âœˆï¸ AviÃ³n (F1=0.86) - Forma Ãºnica con alas
- ğŸ¸ Rana (F1=0.85) - Color verde Ãºnico

### Estudio de AblaciÃ³n

**Ranking de importancia de tÃ©cnicas:**

1. ğŸ¥‡ **Data Augmentation** â†’ -4.2% sin ella (la mÃ¡s crÃ­tica)
2. ğŸ¥ˆ **L2 Regularization** â†’ -1.7% sin ella
3. ğŸ¥‰ **Dropout** â†’ -1.3% sin ella

**ConclusiÃ³n:** Data Augmentation multiplica el dataset efectivamente 5-10Ã—, siendo indispensable con solo 40k imÃ¡genes de entrenamiento.

### ComparaciÃ³n de Optimizadores

| Optimizador | Convergencia | Estabilidad | Test Acc |
|-------------|--------------|-------------|----------|
| Adam + ReduceLR | RÃ¡pida (3-5 Ã©pocas) | Oscilaciones | 78.2% |
| SGD + CosineDecay | Lenta (7-10 Ã©pocas) | Muy suave | 78.5% |

**RecomendaciÃ³n:** Adam para prototipado rÃ¡pido; SGD para modelos finales en producciÃ³n.

---

## ğŸ“– DocumentaciÃ³n Completa

### Informe Ejecutivo

El informe completo de 2 pÃ¡ginas estÃ¡ incluido en el notebook principal e incluye:

- âœ… Problema y datos (CIFAR-10, splits, preprocesamiento)
- âœ… MetodologÃ­a (evoluciÃ³n de arquitecturas)
- âœ… Resultados principales (tablas, figuras, mÃ©tricas)
- âœ… Cinco decisiones justificadas tÃ©cnicamente
- âœ… Limitaciones y prÃ³ximos pasos
- âœ… Recuadro de reproducibilidad completo

### Archivos Clave de Trazabilidad

| Archivo | Contenido |
|---------|-----------|
| `results/params.yaml` | Configuraciones de todos los experimentos |
| `results/metrics.json` | MÃ©tricas completas (val_acc, test_acc, best_model) |
| `results/data_meta.json` | Hash de datos, formas, normalizaciÃ³n |
| `results/history_*.csv` | Historial Ã©poca por Ã©poca de cada modelo |
| `env/requirements.txt` | Dependencias congeladas |
| `env/ENVIRONMENT.md` | Versiones de Python, TensorFlow, GPU |

---

## ğŸ“ Hallazgos Clave

### 1. CNNs superan dramÃ¡ticamente a MLPs en visiÃ³n (+22%)

**RazÃ³n:** Sesgo inductivo espacial + comparticiÃ³n de pesos + invariancia translacional

### 2. Data Augmentation es la tÃ©cnica mÃ¡s impactante (+4%)

**RazÃ³n:** Multiplica dataset 5-10Ã— efectivamente, indispensable con 40k imÃ¡genes

### 3. MÃ¡s profundidad â‰  Siempre mejor (rendimientos decrecientes)

**RazÃ³n:** CNN 3B tiene +100% parÃ¡metros y +50% tiempo pero solo +0-1% accuracy

### 4. Gato/Perro son las clases mÃ¡s difÃ­ciles de distinguir

**RazÃ³n:** CuadrÃºpedos con proporciones similares; detalles faciales perdidos a 32Ã—32px

### 5. Adam converge mÃ¡s rÃ¡pido, SGD encuentra mejores mÃ­nimos

**RazÃ³n:** Adam adapta LR por parÃ¡metro (rÃ¡pido); SGD+momentum explora mejor (robusto)

---

## ğŸ”® Mejoras Futuras Propuestas

### 1ï¸âƒ£ Label Smoothing + Focal Loss

- **Mejora esperada:** +1.5-2.5% â†’ 79-81% accuracy
- **Esfuerzo:** Bajo (20-30 lÃ­neas de cÃ³digo)
- **Beneficio:** Reduce overconfidence, focaliza en clases difÃ­ciles

### 2ï¸âƒ£ Transfer Learning (MobileNetV2)

- **Mejora esperada:** +6-9% â†’ 83-87% accuracy
- **Esfuerzo:** Moderado (40-60 lÃ­neas)
- **Beneficio:** Aprovecha ImageNet (1.2M imÃ¡genes pre-entrenadas)

### 3ï¸âƒ£ Otras tÃ©cnicas avanzadas

- Mixup / CutMix para mayor robustez
- AutoAugment para polÃ­ticas Ã³ptimas automÃ¡ticas
- Ensemble de 3-5 modelos
- Arquitecturas modernas (EfficientNet, Vision Transformer)

---

## ğŸ“ CitaciÃ³n

Si utilizas este proyecto o cÃ³digo, por favor cita:

```bibtex
@misc{cifar10_cnn_2025,
  author = {Daniel WP},
  title = {ClasificaciÃ³n de ImÃ¡genes CIFAR-10 con CNNs},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/dwp/IA_P3_CIFAR10_WillsonDaniel}
}
```

---

## ğŸ‘¤ Autor

**Daniel Willson Pastor**

- GitHub: dwp28(https://github.com/dwp28)
- Email: 
- Universidad: UNIE

---

## ğŸ“… Timeline del Proyecto

- **Inicio:** Noviembre 2025
- **PROMPT 1-3:** Setup + Baselines (MLP, CNN simple)
- **PROMPT 4-6:** RegularizaciÃ³n + Arquitecturas profundas
- **PROMPT 7-9:** AnÃ¡lisis + AblaciÃ³n + Optimizadores
- **PROMPT 10:** Informe final + Release
- **Release v1.0:** Noviembre 2025

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

## ğŸ™ Agradecimientos

- **Dataset:** [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) por Alex Krizhevsky, Vinod Nair, Geoffrey Hinton
- **Plataforma:** [Google Colab](https://colab.research.google.com/) por recursos GPU gratuitos
- **Frameworks:** [TensorFlow](https://www.tensorflow.org/) y [Keras](https://keras.io/)
- **Comunidad:** Stack Overflow, TensorFlow Docs, Papers with Code

---

## ğŸ“ Contacto y Soporte

Â¿Preguntas, bugs o sugerencias?

- ğŸ› **Issues:** [GitHub Issues](https://github.com/dwp/IA_P3_CIFAR10_WillsonDaniel/issues)
- ğŸ’¬ **Discusiones:** [GitHub Discussions](https://github.com/dwp28/IA_P3_CIFAR10_WillsonDaniel/discussions)
- ğŸ“§ **Email:**

---

<div align="center">

**â­ Si este proyecto te ha sido Ãºtil, considera darle una estrella en GitHub â­**


</div>

---

<div align="center">
  <sub>Desarrollado con â¤ï¸ usando TensorFlow y Google Colab</sub>
</div>