# ============================================
# CONFIGURACIÓN INICIAL DEL PROYECTO
# ============================================

# Datos
dataset: "CIFAR-10"
seed: 42
normalizacion: "division_255"
train_size: 0.8
valid_size: 0.2
estratificado: true

# Arquitectura (baseline inicial)
modelo_tipo: "CNN_simple"
bloques_conv: 2
filtros:
  - 32
  - 64
kernel_size: [3, 3]
pooling: "MaxPooling2D"
pool_size: [2, 2]
dense_units: 128
dropout_rate: 0.5
activation_hidden: "relu"
activation_output: "softmax"

# Entrenamiento
optimizer: "adam"
learning_rate: 0.001
batch_size: 64
epochs: 30
loss_function: "categorical_crossentropy"
metrics:
  - "accuracy"

# Regularización
augmentation_enabled: false
early_stopping: false
reduce_lr_on_plateau: false

# Trazabilidad
fecha_configuracion: "14/11/2025"
<<<<<<< HEAD
=======

# ============================================
# PROMPT 2: CONFIGURACIÓN MLP BASELINE
# ============================================

mlp_baseline:
  arquitectura: "MLP"
  capas:
    - tipo: "Flatten"
    - tipo: "Dense"
      units: 256
      activation: "relu"
    - tipo: "Dropout"
      rate: 0.5
    - tipo: "Dense"
      units: 10
      activation: "softmax"
  
  parametros_totales: 789,258
  
  entrenamiento:
    optimizer: "adam"
    learning_rate: 0.001
    batch_size: 64
    epochs: 10
    loss: "categorical_crossentropy"
    metrics: ["accuracy"]
  
  resultados:
    val_loss: 1.8994
    val_accuracy: 0.3251
    test_loss: 1.8994
    test_accuracy: 0.3154
  
  fecha_experimento: "14/11/2025"
